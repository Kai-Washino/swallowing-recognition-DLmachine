{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a1e364",
   "metadata": {},
   "source": [
    "# csv出力\n",
    "- pandasDateFremeにデータを格納する\n",
    "- それを全てcsv出力する\n",
    "\n",
    "pandasDateFrameに格納するのは\n",
    "- 嚥下の開始時間\n",
    "- 嚥下の終了時間\n",
    "\n",
    "ステップとしては\n",
    "1. 必要なライブラリをimport\n",
    "2. wavファイルのパスを取得\n",
    "3. wavファイルをモデルで解析\n",
    "4. 結果をdfに格納\n",
    "5. csvファイルを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5dcc1",
   "metadata": {},
   "source": [
    "## 必要なライブラリをimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9d4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 09:12:43.026822: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 09:12:43.068460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 09:12:43.732862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc607144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "current_file_path = pathlib.Path(os.getcwd())\n",
    "parent_dir = current_file_path.parent\n",
    "import swallowing_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a3077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swallowing_recognition import wavelet\n",
    "from swallowing_recognition import dataset\n",
    "from swallowing_recognition import long_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e9cb6",
   "metadata": {},
   "source": [
    "## wavファイルのパスを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10min_kanata_20240229_2.wav', '10min_oda_20240227_2.wav', '10min_osawa_20240227_5.wav', '10min_tsuji_20240229_3.wav', '10min_matsumi_20240227_5.wav', '10min_oda_20240227_5.wav', '10min_shibata_20240229_1.wav', '10min_tsuji_20240229_1.wav', '10min_matsumi_20240227_2.wav', '10min_shibata_20240229_4.wav', '10min_oda_20240227_4.wav', '10min_kanata_20240229_5.wav', '10min_matsumi_20240227_1.wav', '10min_osawa_20240227_3.wav', '10min_matsumi_20240227_3.wav', '10min_tsuji_20240229_4.wav', '10min_osawa_20240227_2.wav', '10min_kanata_20240229_3.wav', '10min_matsumi_20240227_4.wav', '10min_tsuji_20240229_2.wav', '10min_shibata_20240229_5.wav', '10min_tsuji_20240229_5.wav', '10min_osawa_20240227_4.wav', '10min_kanata_20240229_1.wav', '10min_kanata_20240229_4.wav', '10min_shibata_20240229_2.wav', '10min_osawa_20240227_1.wav', '10min_shibata_20240229_3.wav', '10min_oda_20240227_3.wav', '10min_oda_20240227_1.wav']\n"
     ]
    }
   ],
   "source": [
    "directory_path = parent_dir \n",
    "folder_path = directory_path / 'experiment'/ 'experiment_1'\n",
    "wav_files = [file for file in os.listdir(folder_path) if file.endswith('.wav')]\n",
    "print(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58447d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = [long_audio.Long_audio(folder_path / wav_file) for wav_file in wav_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69dd97",
   "metadata": {},
   "source": [
    "## wavファイルを解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf8eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 09:33:57.919589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22064 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 09:34:04.272763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-03-11 09:34:04.455686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 123ms/step\n",
      "Predicted classes: [1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1]\n",
      "(157, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 72ms/step\n",
      "Predicted classes: [1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
      " 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1]\n",
      "(108, 224, 224, 3)\n",
      "4/4 [==============================] - 1s 71ms/step\n",
      "Predicted classes: [0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1]\n",
      "(57, 224, 224, 3)\n",
      "2/2 [==============================] - 2s 197ms/step\n",
      "Predicted classes: [0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
      " 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1]\n",
      "(143, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 62ms/step\n",
      "Predicted classes: [0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(130, 224, 224, 3)\n",
      "5/5 [==============================] - 2s 61ms/step\n",
      "Predicted classes: [0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1]\n",
      "(134, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 55ms/step\n",
      "Predicted classes: [1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "(231, 224, 224, 3)\n",
      "8/8 [==============================] - 2s 44ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 1 0 1]\n",
      "(27, 224, 224, 3)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted classes: [0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1]\n",
      "(53, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 181ms/step\n",
      "Predicted classes: [0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1]\n",
      "(79, 224, 224, 3)\n",
      "3/3 [==============================] - 1s 29ms/step\n",
      "Predicted classes: [1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1]\n",
      "(23, 224, 224, 3)\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57317fb760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1]\n",
      "(78, 224, 224, 3)\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58dfb59990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 91ms/step\n",
      "Predicted classes: [1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 0]\n",
      "(51, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 194ms/step\n",
      "Predicted classes: [0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1\n",
      " 1 0 0 0 1 1 1 1 1 0 1 1 0 1]\n",
      "(50, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 171ms/step\n",
      "Predicted classes: [1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 0]\n",
      "(103, 224, 224, 3)\n",
      "4/4 [==============================] - 1s 30ms/step\n",
      "Predicted classes: [1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
      " 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1]\n",
      "(41, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 147ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0]\n",
      "(44, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 34ms/step\n",
      "Predicted classes: [1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 1]\n",
      "(111, 224, 224, 3)\n",
      "4/4 [==============================] - 1s 27ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      "(155, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 27ms/step\n",
      "Predicted classes: [1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
      " 1 0 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0\n",
      " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 1 0 0 0]\n",
      "(256, 224, 224, 3)\n",
      "8/8 [==============================] - 1s 27ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1]\n",
      "(123, 224, 224, 3)\n",
      "4/4 [==============================] - 1s 26ms/step\n",
      "Predicted classes: [1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 1 1 0 0]\n",
      "(68, 224, 224, 3)\n",
      "3/3 [==============================] - 1s 93ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1]\n",
      "(103, 224, 224, 3)\n",
      "4/4 [==============================] - 2s 28ms/step\n",
      "Predicted classes: [1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 224, 224, 3)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
      "(143, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 26ms/step\n",
      "Predicted classes: [0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      "(42, 224, 224, 3)\n",
      "2/2 [==============================] - 1s 161ms/step\n",
      "Predicted classes: [0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1\n",
      " 1 1 1 1 0]\n",
      "(109, 224, 224, 3)\n",
      "4/4 [==============================] - 2s 71ms/step\n",
      "Predicted classes: [1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1]\n",
      "(147, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 26ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0\n",
      " 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(147, 224, 224, 3)\n",
      "5/5 [==============================] - 1s 29ms/step\n",
      "Predicted classes: [1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
      " 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "current_path = directory_path\n",
    "model_path = current_path / 'ipynb_swallowing' / '20240220_binary_ep50_bs32_v2.keras'\n",
    "for wav in wavs:\n",
    "    wav.predict(model_path, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4317f",
   "metadata": {},
   "source": [
    "## 結果をdfに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f74866b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_arrays = []\n",
    "end_arrays = []\n",
    "for wav in wavs:\n",
    "    start_arrays.append(wav.swallowing_start_idxs/44100)\n",
    "    end_arrays.append(wav.swallowing_end_idxs/44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e3612f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(start_arrays[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f5e6696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
      "/tmp/ipykernel_1666751/755424680.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'wav_file': wav_files})\n",
    "for start_time, end_time in zip(start_arrays, end_arrays):    \n",
    "    for i in range(100):    \n",
    "        df[f'start_{i+1}'] = df.apply(lambda row, i=i: start_arrays[row.name][i] if i < len(start_arrays[row.name]) else np.nan, axis=1)\n",
    "        df[f'end_{i+1}'] = df.apply(lambda row, i=i: end_arrays[row.name][i] if i < len(end_arrays[row.name]) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2136617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        wav_file     start_1       end_1     start_2  \\\n",
      "0    10min_kanata_20240229_2.wav  184.498095  185.135556  203.694082   \n",
      "1       10min_oda_20240227_2.wav   13.131905   13.447891   20.293832   \n",
      "2     10min_osawa_20240227_5.wav    7.134422    7.621293   13.613651   \n",
      "3     10min_tsuji_20240229_3.wav   23.421905   23.953016   59.438209   \n",
      "4   10min_matsumi_20240227_5.wav    0.195465    0.693107   12.482925   \n",
      "5       10min_oda_20240227_5.wav    0.490454    0.864490    3.282404   \n",
      "6   10min_shibata_20240229_1.wav   22.228707   23.202766  100.671111   \n",
      "7     10min_tsuji_20240229_1.wav   12.274354   12.652971   42.517687   \n",
      "8   10min_matsumi_20240227_2.wav    0.005465    1.489501    5.543220   \n",
      "9   10min_shibata_20240229_4.wav    4.343243    5.503537   14.919388   \n",
      "10      10min_oda_20240227_4.wav   21.381111   23.058481   81.285828   \n",
      "11   10min_kanata_20240229_5.wav  134.847460  134.894694  174.810567   \n",
      "12  10min_matsumi_20240227_1.wav   58.869297   59.811134   61.425782   \n",
      "13    10min_osawa_20240227_3.wav    1.880363    2.114603   67.464059   \n",
      "14  10min_matsumi_20240227_3.wav    8.676757    8.717120   81.842494   \n",
      "15    10min_tsuji_20240229_4.wav   36.528526   36.917007   64.284580   \n",
      "16    10min_osawa_20240227_2.wav   75.108776   76.399546  112.080272   \n",
      "17   10min_kanata_20240229_3.wav   95.770340   95.893605  210.071769   \n",
      "18  10min_matsumi_20240227_4.wav   31.636825   31.975850   37.156327   \n",
      "19    10min_tsuji_20240229_2.wav    8.630363    9.239410   11.944127   \n",
      "20  10min_shibata_20240229_5.wav   34.115669   34.778322   56.220998   \n",
      "21    10min_tsuji_20240229_5.wav    8.888776    9.515850   12.325193   \n",
      "22    10min_osawa_20240227_4.wav  180.981746  181.652063  181.902630   \n",
      "23   10min_kanata_20240229_1.wav   10.323129   10.367687   17.594059   \n",
      "24   10min_kanata_20240229_4.wav  142.324580  142.349683  162.881429   \n",
      "25  10min_shibata_20240229_2.wav    1.361247    1.910000   13.084898   \n",
      "26    10min_osawa_20240227_1.wav    5.888345    6.709955   79.207075   \n",
      "27  10min_shibata_20240229_3.wav   10.355556   10.462744   28.179093   \n",
      "28      10min_oda_20240227_3.wav   19.974331   19.999184   37.001247   \n",
      "29      10min_oda_20240227_1.wav   17.902744   19.165624   35.609728   \n",
      "\n",
      "         end_2     start_3       end_3     start_4       end_4     start_5  \\\n",
      "0   203.715465  251.300408  251.314580  252.465329  252.493243  303.636417   \n",
      "1    20.316916   23.677166   23.992494   25.913832   26.157506   41.580635   \n",
      "2    13.683175   24.108526   24.855964   25.274127   25.373129   97.490612   \n",
      "3    59.701905   60.092812   61.202426   65.495374   65.754376   77.955601   \n",
      "4    12.924603   14.449274   14.807914   52.901179   53.384671   62.033832   \n",
      "5     3.496236   11.558095   11.572494   12.498889   12.519592   18.646349   \n",
      "6   100.689705  147.843673  147.876757  154.478435  154.495057  159.718549   \n",
      "7    42.596054   70.600907   70.626349   78.364989   78.418050   80.833991   \n",
      "8     6.203810   57.231315   57.896304   64.510431   65.886893   96.957211   \n",
      "9    15.575283  103.552812  104.198889  143.929478  144.873673  145.155805   \n",
      "10   82.532041   91.863288   92.478753  177.301837  178.326916  191.887234   \n",
      "11  174.919524  180.826259  181.634626  248.474671  248.500136  337.238027   \n",
      "12   62.053492   76.215760   76.814195   89.763265   90.814989   94.069138   \n",
      "13   69.009501   76.949410   77.856190   80.918821   81.628980   93.744921   \n",
      "14   82.665442   99.852132  100.407029  148.205170  148.903900  177.633991   \n",
      "15   64.424649  131.746621  132.342222  155.187823  155.407438  170.771565   \n",
      "16  112.927642  115.265397  116.191678  122.925986  123.833469  145.697256   \n",
      "17  210.111338  217.149705  217.760499  250.114490  250.294104  373.289501   \n",
      "18   37.360816  228.876893  229.718821  246.000612  246.067211  246.738413   \n",
      "19   12.556100   27.680000   27.884172   34.231474   34.846281   75.883492   \n",
      "20   56.536757   96.698481   96.714354  168.972948  169.890635  178.482086   \n",
      "21   12.463991   15.003129   15.561950   20.872200   21.442313   29.216463   \n",
      "22  183.253288  183.604263  184.754512  216.077438  216.737392  219.265828   \n",
      "23   17.824512   21.602222   21.854649   26.379025   26.486735   61.028277   \n",
      "24  162.941315  163.436395  163.461429  246.629456  246.661519         NaN   \n",
      "25   13.367664   28.369365   28.838730   60.707596   61.171202   63.313764   \n",
      "26   80.189592  186.399320  187.525306  203.445306  203.759388  245.309252   \n",
      "27   28.207823   55.458821   55.649773  101.352494  101.486327  104.003175   \n",
      "28   37.020023   39.422630   39.842880   50.540000   51.549819  136.817710   \n",
      "29   35.649796   42.064467   42.085556   56.852948   56.875374   57.453175   \n",
      "\n",
      "    ...  start_96  end_96  start_97  end_97  start_98  end_98  start_99  \\\n",
      "0   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "1   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "2   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "3   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "4   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "5   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "6   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "7   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "8   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "9   ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "10  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "11  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "12  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "13  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "14  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "15  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "16  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "17  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "18  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "19  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "20  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "21  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "22  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "23  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "24  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "25  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "26  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "27  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "28  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "29  ...       NaN     NaN       NaN     NaN       NaN     NaN       NaN   \n",
      "\n",
      "    end_99  start_100  end_100  \n",
      "0      NaN        NaN      NaN  \n",
      "1      NaN        NaN      NaN  \n",
      "2      NaN        NaN      NaN  \n",
      "3      NaN        NaN      NaN  \n",
      "4      NaN        NaN      NaN  \n",
      "5      NaN        NaN      NaN  \n",
      "6      NaN        NaN      NaN  \n",
      "7      NaN        NaN      NaN  \n",
      "8      NaN        NaN      NaN  \n",
      "9      NaN        NaN      NaN  \n",
      "10     NaN        NaN      NaN  \n",
      "11     NaN        NaN      NaN  \n",
      "12     NaN        NaN      NaN  \n",
      "13     NaN        NaN      NaN  \n",
      "14     NaN        NaN      NaN  \n",
      "15     NaN        NaN      NaN  \n",
      "16     NaN        NaN      NaN  \n",
      "17     NaN        NaN      NaN  \n",
      "18     NaN        NaN      NaN  \n",
      "19     NaN        NaN      NaN  \n",
      "20     NaN        NaN      NaN  \n",
      "21     NaN        NaN      NaN  \n",
      "22     NaN        NaN      NaN  \n",
      "23     NaN        NaN      NaN  \n",
      "24     NaN        NaN      NaN  \n",
      "25     NaN        NaN      NaN  \n",
      "26     NaN        NaN      NaN  \n",
      "27     NaN        NaN      NaN  \n",
      "28     NaN        NaN      NaN  \n",
      "29     NaN        NaN      NaN  \n",
      "\n",
      "[30 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b24e3f",
   "metadata": {},
   "source": [
    "## CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90991777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('30data_30min.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c35381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2-washino",
   "language": "python",
   "name": "washino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
